{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Input \u001B[0;32mIn [1]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m nn, optim\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnp\u001B[39;00m\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import mpl_toolkits.mplot3d.axes3d as p3\n",
    "from sklearn.datasets import make_swiss_roll\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "device = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "n_samples = 1500\n",
    "noise = 0.05\n",
    "X, colors = make_swiss_roll(n_samples, noise)\n",
    "\n",
    "X = MinMaxScaler().fit_transform(X)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = p3.Axes3D(fig)\n",
    "ax.scatter(X[:,0], X[:,1], X[:,2], c=colors, cmap=plt.cm.jet)\n",
    "plt.title('Swiss roll')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x = torch.from_numpy(X).to(device)\n",
    "\n",
    "class Autoencoder(nn.Module):\n",
    "    \"\"\"Makes the main denoising auto\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    in_shape [int] : input shape\n",
    "    enc_shape [int] : desired encoded shape\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_shape, enc_shape):\n",
    "        super(Autoencoder, self).__init__()\n",
    "\n",
    "        self.encode = nn.Sequential(\n",
    "            nn.Linear(in_shape, 128),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(64, enc_shape),\n",
    "        )\n",
    "\n",
    "        self.decode = nn.Sequential(\n",
    "            nn.BatchNorm1d(enc_shape),\n",
    "            nn.Linear(enc_shape, 64),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128, in_shape)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encode(x)\n",
    "        x = self.decode(x)\n",
    "        return x\n",
    "\n",
    "encoder = Autoencoder(in_shape=3, enc_shape=2).double().to(device)\n",
    "\n",
    "error = nn.MSELoss()\n",
    "\n",
    "optimizer = optim.Adam(encoder.parameters())"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
