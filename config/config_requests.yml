task: 'requests'
size_bea: 'all' #'15360' #'10240' # take a subset from the total 57548 files for each: wavs and txt

hf_cache_dir: '/srv/data/egasj/hf_cache/'
#hf_cache_dir: '/home/user/Documents/hf_cache/'
#hf_cache_dir: '/media/jvel/data/hf_cache/'

pretrained_model_details:
#  checkpoint_path: '/srv/data/egasj/code/wav2vec2_patho/wav2vec2-large-xlsr-beaBase-20percent/checkpoint-51800'

#  checkpoint_path: '/home/user/Documents/data/bea16k_hungarian/bea16k_3.0_hungarian/checkpoint-3390'
#  checkpoint_path: '/home/user/Documents/data/bea16k_hungarian/bea16k_5.0_hungarian/checkpoint-5650'

#  checkpoint_path: '/media/jvel/data/audio/Bea-base/beast-xls-r-300m_v0.1/beast-xls-r-300m/checkpoint'

#  checkpoint_path: 'facebook/wav2vec2-large-xlsr-53'
  checkpoint_path: 'jonatasgrosman/wav2vec2-large-xlsr-53-hungarian'
#  checkpoint_path: 'speechbrain/spkrec-ecapa-voxceleb'

#  checkpoint_path: '/srv/data/egasj/code/wav2vec2_patho/runs/bea-base-train-flat_10.0_no_pause_speech/checkpoint-6000'

#  checkpoint_path: 'facebook/wav2vec2-base-960h'
#   checkpoint_path: 'facebook/wav2vec2-large-960h'
#  checkpoint_path: 'jonatasgrosman/wav2vec2-large-xlsr-53-english'
#  checkpoint_path: 'm3hrdadfi/wav2vec2-xlsr-greek-speech-emotion-recognition'
#  checkpoint_path: 'm3hrdadfi/wav2vec2-xlsr-persian-speech-emotion-recognition'
#  checkpoint_path: 'facebook/wav2vec2-xls-r-300m'
#  checkpoint_path: 'facebook/wav2vec2-xls-r-1b'
#  checkpoint_path: 'facebook/data2vec-audio-base-960h'
paths:
#  to_labels: 'data/10_narrative_recall/labels_maci.csv'
#  to_labels: 'data/requests/labels_local.csv' # jvel PC
  to_labels: 'data/requests/' # deep 4
  to_save_metadata: 'data/requests/'
#  audio_path: '/media/jvel/data/audio/DEPISDA_16k'
  audio_path: '/srv/data/egasj/corpora/requests/'
  out_embeddings: 'data/requests/embeddings/'
  output_results: 'data/requests/results/experiments.csv'

feature_combination: False
sampling_rate: 16000
# This is read from ../sclerosis_multiple.py
discrimination:
  emb_type: 'hiddens'
#  emb_type: 'convs'
shuffle_data: True
# data preprocessing
dimension_reduction:
  method: None #'vae'  # pca, autoencoder (basic), vae (variational autoencoder)
  pca:
    # best n_components = 193 (0.95); 302 (0.97) ==> hiddens;
    # best n_components = 79 (0.95); 118 (0.97) ==> convs;
    n_components: 0.95  # first 4 => 0.97
    save_pca: False
#    pca_path: "data/bea-base-train-flat/dim_red/bea_train_flat_pca" #.pkl
    pca_path: "data/bea-base-train-flat/dim_red/bea_train_flat_pca_comb" #.pkl
  autoencoder:
    encoder_size: 471 # akin to n_components for the autoencoder  #178 fpr convs; 471 hiddens
    num_epochs: 1500
    save_path: "data/bea-base-train-flat/dim_red/autoencoder/bea_train_flat"

data_scaling:
  save_scaling_model: False
#  scaling_model_path: "data/bea-base-train-flat/dim_red/train_flat" #.pkl
  scaling_model_path: "data/bea-base-train-flat/dim_red/compare_func_xv" #.pkl
   # "minmax" "standard" "robust" "normalizer" null
  scaler_type: "robust"
